{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# setting directories\n",
    "ROOT_DIR = os.path.abspath('../input')\n",
    "TRAIN_JPEG_DIR = os.path.join(ROOT_DIR, 'train-jpg')\n",
    "TEST_JPEG_DIR = os.path.join(ROOT_DIR, 'test-jpg-v2')\n",
    "TRAIN_TIF_DIR = os.path.join(ROOT_DIR, 'train-tif-v2')\n",
    "TEST_TIF_DIR = os.path.join(ROOT_DIR, 'test-tif-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    im = cv2.imread(path)\n",
    "    return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    \"\"\"Normalizes images with Imagenet stats.\"\"\"\n",
    "    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
    "    return (im - imagenet_stats[0]) / imagenet_stats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = os.listdir(TRAIN_JPEG_DIR)\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = os.path.join(TRAIN_JPEG_DIR, 'train_9203.jpg')\n",
    "im = read_image(sample_path)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical size: 256x256 so should be able to train directly without resizing\n",
    "dims = [read_image(os.path.join(TRAIN_JPEG_DIR, p)).shape for p in training_images[:50]]\n",
    "dims[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_names = list(os.listdir(TRAIN_JPEG_DIR))\n",
    "train_labels_df = pd.read_csv(os.path.join(ROOT_DIR, 'train_v2.csv'))\n",
    "test_file_names = list(os.listdir(TEST_JPEG_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_IDs = [f.split('.')[0] for f in train_file_names]\n",
    "test_IDs = [f.split('.')[0] for f in test_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_train_IDs, val_IDs = train_test_split(train_IDs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {'train': train_IDs, 'inner_train': inner_train_IDs, \n",
    "             'validation': val_IDs, 'test': test_IDs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "for tag in train_labels_df.tags:\n",
    "    train_labels.append(tag.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "for i, row in enumerate(train_labels_df.itertuples()):\n",
    "    labels[row.image_name] = train_labels[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(im, r, c, target_r, target_c):\n",
    "    return im[r:r+target_r, c:c+target_c]\n",
    "\n",
    "# random crop to the original size\n",
    "def random_crop(x, r_pix=8):\n",
    "    \"\"\"Returns a random crop\"\"\"\n",
    "    r, c, *_ = x.shape\n",
    "    r, c, *_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    rand_r = random.uniform(0, 1)\n",
    "    rand_c = random.uniform(0, 1)\n",
    "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
    "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
    "    return crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "def center_crop(x, r_pix=8):\n",
    "    r, c, *_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    return crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "\n",
    "def rotate_cv(im, deg, mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
    "    \"\"\" Rotates an image by deg degrees\"\"\"\n",
    "    r, c, *_ = im.shape\n",
    "    M = cv2.getRotationMatrix2D((c/2, r/2), deg, 1)\n",
    "    return cv2.warpAffine(im, M, (c,r), borderMode=mode, \n",
    "                          flags=cv2.WARP_FILL_OUTLIERS+interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanetDataset(Dataset):\n",
    "    def __init__(self, folder_path, list_IDs, labels, transforms=False):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "        self.folder_path = folder_path\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name = self.list_IDs[idx]\n",
    "        file_path = os.path.join(self.folder_path, name + '.jpg')\n",
    "        x = cv2.imread(file_path).astype(np.float32)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) / 255\n",
    "        if self.transforms:\n",
    "            rdeg = (np.random.random() - 0.50) * 20\n",
    "            x = rotate_cv(x, rdeg)\n",
    "            x = random_crop(x)\n",
    "            if np.random.random() > 0.5:\n",
    "                x = np.fliplr(x).copy()\n",
    "            else:\n",
    "                x = center_crop(x)\n",
    "        x = normalize(x)\n",
    "        if self.labels is not None:\n",
    "            y = torch.from_numpy(self.labels[name])\n",
    "            return np.rollaxis(x, 2), y\n",
    "        return np.rollaxis(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_train_ds = PlanetDataset(TRAIN_JPEG_DIR, partition['inner_train'], labels)\n",
    "val_ds = PlanetDataset(TRAIN_JPEG_DIR, partition['validation'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "inner_train_dl = DataLoader(inner_train_ds, batch_size=batch_size, shuffle=True) \n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(2304, 256)\n",
    "        self.fc2 = nn.Linear(256, 17)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        # freezing parameters\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        # convolutional layers of resnet34\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.top_model = nn.Sequential(*layers).cuda()\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.top_model(x))\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(num_classes=17).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = iter(inner_train_dl).next()\n",
    "x = x.cuda().float()\n",
    "y = y.cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sigmoid = F.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sigmoid.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta_score(y.cpu(), output_sigmoid.cpu() > 0.5, beta=2, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.binary_cross_entropy_with_logits(y, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, val_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    sum_f2 = 0\n",
    "    \n",
    "    for x, y in val_dl:\n",
    "        batch = y.shape[0]\n",
    "        x = x.cuda().float()\n",
    "        y = y.cuda().float()\n",
    "        out = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        pred = F.sigmoid(out) > 0.5\n",
    "        sum_f2 += batch*(fbeta_score(y.cpu(), pred.cpu() > 0.5, beta=2, average='macro'))\n",
    "        total += batch\n",
    "    return sum_loss / total, sum_f2 / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics(net, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, val_dl, epochs=10, learning_rate=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            batch_size = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda().float()\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += batch_size\n",
    "            sum_loss += batch_size*(loss.item())\n",
    "        train_loss = sum_loss / total\n",
    "        val_loss, val_f2 = val_metrics(model, val_dl)\n",
    "        print(\"Epoch: %d, Train loss: %.3f, val loss: %.3f, val f2: %.3f\" % (epoch+1, train_loss, val_loss, val_f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(num_classes=17).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "inner_train_dl = DataLoader(inner_train_ds, batch_size=batch_size, shuffle=True) \n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, inner_train_dl, val_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
