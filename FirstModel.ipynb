{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import fbeta_score\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import models","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# setting directories\nROOT_DIR = os.path.abspath('../input')\nTRAIN_JPEG_DIR = os.path.join(ROOT_DIR, 'train-jpg')\nTEST_JPEG_DIR = os.path.join(ROOT_DIR, 'test-jpg-v2')\nTRAIN_TIF_DIR = os.path.join(ROOT_DIR, 'train-tif-v2')\nTEST_TIF_DIR = os.path.join(ROOT_DIR, 'test-tif-v3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(path):\n    im = cv2.imread(path)\n    return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(im):\n    \"\"\"Normalizes images with Imagenet stats.\"\"\"\n    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n    return (im - imagenet_stats[0]) / imagenet_stats[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_images = os.listdir(TRAIN_JPEG_DIR)\nprint(training_images[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_path = os.path.join(TRAIN_JPEG_DIR, 'train_9203.jpg')\nim = read_image(sample_path)\nplt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# typical size: 256x256 so should be able to train directly without resizing\ndims = [read_image(os.path.join(TRAIN_JPEG_DIR, p)).shape for p in training_images[:50]]\ndims[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file_names = list(os.listdir(TRAIN_JPEG_DIR))\ntrain_labels_df = pd.read_csv(os.path.join(ROOT_DIR, 'train_v2.csv'))\ntest_file_names = list(os.listdir(TEST_JPEG_DIR))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_IDs = [f.split('.')[0] for f in train_file_names]\ntest_IDs = [f.split('.')[0] for f in test_file_names]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inner_train_IDs, val_IDs = train_test_split(train_IDs, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"partition = {'train': train_IDs, 'inner_train': inner_train_IDs, \n             'validation': val_IDs, 'test': test_IDs}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = []\nfor tag in train_labels_df.tags:\n    train_labels.append(tag.split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlb = MultiLabelBinarizer()\ntrain_labels = mlb.fit_transform(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = {}\nfor i, row in enumerate(train_labels_df.itertuples()):\n    labels[row.image_name] = train_labels[i]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop(im, r, c, target_r, target_c):\n    return im[r:r+target_r, c:c+target_c]\n\n# random crop to the original size\ndef random_crop(x, r_pix=8):\n    \"\"\"Returns a random crop\"\"\"\n    r, c, *_ = x.shape\n    r, c, *_ = x.shape\n    c_pix = round(r_pix*c/r)\n    rand_r = random.uniform(0, 1)\n    rand_c = random.uniform(0, 1)\n    start_r = np.floor(2*rand_r*r_pix).astype(int)\n    start_c = np.floor(2*rand_c*c_pix).astype(int)\n    return crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n\ndef center_crop(x, r_pix=8):\n    r, c, *_ = x.shape\n    c_pix = round(r_pix*c/r)\n    return crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n\n\ndef rotate_cv(im, deg, mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n    \"\"\" Rotates an image by deg degrees\"\"\"\n    r, c, *_ = im.shape\n    M = cv2.getRotationMatrix2D((c/2, r/2), deg, 1)\n    return cv2.warpAffine(im, M, (c,r), borderMode=mode, \n                          flags=cv2.WARP_FILL_OUTLIERS+interpolation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class PlanetDataset(Dataset):\n    def __init__(self, folder_path, list_IDs, labels, transforms=False):\n        self.list_IDs = list_IDs\n        self.labels = labels\n        self.folder_path = folder_path\n        self.transforms = transforms\n    \n    def __len__(self):\n        return len(self.list_IDs)\n    \n    def __getitem__(self, idx):\n        name = self.list_IDs[idx]\n        file_path = os.path.join(self.folder_path, name + '.jpg')\n        x = cv2.imread(file_path).astype(np.float32)\n        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) / 255\n        if self.transforms:\n            rdeg = (np.random.random() - 0.50) * 20\n            x = rotate_cv(x, rdeg)\n            x = random_crop(x)\n            if np.random.random() > 0.5:\n                x = np.fliplr(x).copy()\n            else:\n                x = center_crop(x)\n        x = normalize(x)\n        if self.labels is not None:\n            y = torch.from_numpy(self.labels[name])\n            return np.rollaxis(x, 2), y\n        return np.rollaxis(x, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inner_train_ds = PlanetDataset(TRAIN_JPEG_DIR, partition['inner_train'], labels)\nval_ds = PlanetDataset(TRAIN_JPEG_DIR, partition['validation'], labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\ninner_train_dl = DataLoader(inner_train_ds, batch_size=batch_size, shuffle=True) \nval_dl = DataLoader(val_ds, batch_size=batch_size) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(2304, 256)\n        self.fc2 = nn.Linear(256, 17)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(x.size(0), -1) # Flatten layer\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.sigmoid(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, num_classes):\n        super(Net, self).__init__()\n        resnet = models.resnet34(pretrained=True)\n        # freezing parameters\n        for param in resnet.parameters():\n            param.requires_grad = False\n        # convolutional layers of resnet34\n        layers = list(resnet.children())[:8]\n        self.top_model = nn.Sequential(*layers).cuda()\n        self.fc = nn.Linear(512, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.top_model(x))\n        x = nn.AdaptiveAvgPool2d((1, 1))(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net(num_classes=17).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = iter(inner_train_dl).next()\nx = x.cuda().float()\ny = y.cuda().float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = net(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_sigmoid = F.sigmoid(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_sigmoid.cpu().detach().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fbeta_score(y.cpu(), output_sigmoid.cpu() > 0.5, beta=2, average='macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"F.binary_cross_entropy_with_logits(y, output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_metrics(model, val_dl):\n    model.eval()\n    total = 0\n    sum_loss = 0\n    sum_f2 = 0\n    \n    for x, y in val_dl:\n        batch = y.shape[0]\n        x = x.cuda().float()\n        y = y.cuda().float()\n        out = model(x)\n        loss = F.binary_cross_entropy_with_logits(out, y)\n        sum_loss += batch*(loss.item())\n        pred = F.sigmoid(out) > 0.5\n        sum_f2 += batch*(fbeta_score(y.cpu(), pred.cpu() > 0.5, beta=2, average='macro'))\n        total += batch\n    return sum_loss / total, sum_f2 / total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_metrics(net, val_dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, train_dl, val_dl, epochs=10, learning_rate=0.01):\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    for epoch in range(epochs):\n        model.train()\n        total = 0\n        sum_loss = 0\n        for x, y in train_dl:\n            batch_size = y.shape[0]\n            x = x.cuda().float()\n            y = y.cuda().float()\n            out = model(x)\n            loss = F.binary_cross_entropy_with_logits(out, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total += batch_size\n            sum_loss += batch_size*(loss.item())\n        train_loss = sum_loss / total\n        val_loss, val_f2 = val_metrics(model, val_dl)\n        print(\"Epoch: %d, Train loss: %.3f, val loss: %.3f, val f2: %.3f\" % (epoch+1, train_loss, val_loss, val_f2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net(num_classes=17).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\ninner_train_dl = DataLoader(inner_train_ds, batch_size=batch_size, shuffle=True) \nval_dl = DataLoader(val_ds, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(net, inner_train_dl, val_dl)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}